{"cells":[{"metadata":{"_uuid":"856f639b-bb7b-4878-8a84-28b3ba41c61b","_cell_guid":"5c88b9c4-6885-4bed-a489-0ac15629d1f1","trusted":true},"cell_type":"code","source":"# %% [code]\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code]\nsample_submission = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\")\n\n# %% [code]\ntrain = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\n\n# %% [code]\ntest = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n\n# %% [code]\npd.options.display.max_columns = 200\n\n# %% [code]\ntrain.head()\n\n# %% [code]\ntest.head()\n\n# %% [code]\nsample_submission.head()\n\n# %% [code]\nfeatures = [\"LotAreaLog\",\"YearBuilt\"]\n\n# %% [code]\nimport matplotlib.pyplot as plt\n\n# %% [code]\nplt.hist(train[\"LotArea\"],bins=100)\nplt.show()\n\n# %% [code]\nplt.scatter(train[\"LotArea\"], train['SalePrice'],s=1)\nplt.show()\n\n# %% [code]\nplt.scatter(np.log1p(train[\"LotArea\"]), np.log1p(train['SalePrice']),s=1)\nplt.title('SalePrice')\nplt.show()\n\n# %% [code]\nplt.scatter(np.log1p(train[\"LotArea\"]), np.log1p(train['SalePrice']),s=1)\nplt.title(\"SalePrice\")\nplt.show()\n\n# %% [code]\ntrain[\"LotAreaLog\"]=np.log1p(train[\"LotArea\"])\ntest[\"LotAreaLog\"]=np.log1p(test[\"LotArea\"])\n\ntrain['SalePriceLog']=np.log1p(train['SalePrice'])\n\n# %% [code]\nplt.hist(train[\"YearBuilt\"],bins = 100)\nplt.show()\n\n# %% [code]\nfrom sklearn.linear_model import SGDRegressor\n\n# %% [code]\nmodel = SGDRegressor()\n\n# %% [code]\nmodel.fit(train[features], train['SalePriceLog'])\n\n# %% [code]\nmodel.predict(train[features])\n\n# %% [code]\nmodel.intercept_\n\n# %% [code]\nmodel.coef_\n\n# %% [code]\nfrom sklearn.model_selection import KFold\n\n# %% [code]\nfrom sklearn.metrics import mean_squared_error\n\n# %% [code]\ntrain.head()\n\n# %% [code]\nkf = KFold(n_splits=5)\nkf.get_n_splits(train)\n\nmse_list = []\nfor i, (train_index, test_index) in enumerate(kf.split(train)):\n #   print(i)\n    X_train, X_test = train.loc[train_index, ['LotAreaLog']], train.loc[test_index, ['LotAreaLog']]\n    y_train, y_test = train.loc[train_index, 'SalePriceLog'],train.loc[test_index, 'SalePriceLog']\n    \n    model.fit(X_train, y_train)\n    X_test_predictions = model.predict(X_test)\n    mse = mean_squared_error( y_true = y_test, y_pred = X_test_predictions)\n    print(i, mse)\n    mse_list.append(mse)\n    \n    plt.scatter( X_test_predictions, y_test, s = 2)\n    plt.ylabel('true value')\n    plt.xlabel('predicted value')\n    plt.plot(y_test, y_test, c='r')\n    plt.show()\n\n# %% [code]\nmse_list\n\n# %% [code]\nprint(np.mean(mse_list), np.std(mse_list))\n\n# %% [code]\nmodel.fit(train[['LotAreaLog']], train['SalePriceLog'])\n\n# %% [code]\ntest_prediction = model.predict(test[['LotAreaLog']])\n\n# %% [code]\nnp.exp(test_prediction)+1\n\n# %% [code]\nsample_submission['SalePrice']=np.exp(test_prediction)+1\n\n# %% [code]\nsample_submission\n\n# %% [code]\nsample_submission.to_csv('sample_submission.csv', index=None)\n\n# %% [markdown]\n# 0.3596154384061611\n\n# %% [code]\nmean_cv_mse_error=np.mean(mse_list)\n\n# %% [code]\nlb=0.62356\nlb2=0.56676\nlb3=0.59476\nlb4=0.60641\nlb5=0.58874\n\n# %% [code]\nmean_cv_mse_error=0.3596154384061611\nmean_cv_mse_error2=0.36314320089276714\nmean_cv_mse_error3=0.34899555992488823\nmean_cv_mse_error4=0.33884875393124864\nmean_cv_mse_error5=0.34844616030525633\n\n# %% [code]\nplt.scatter( [mean_cv_mse_error, mean_cv_mse_error2,mean_cv_mse_error3,mean_cv_mse_error4,mean_cv_mse_error5], [lb, lb2,lb3, lb4,lb5 ]  )\nplt.xlabel('mean_cv_mse_error')\nplt.ylabel('LB')\nplt.show()","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}